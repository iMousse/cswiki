分布式事务
==========

[[toc]]



## 分布式事务问题

本地事务，也就是传统的**单机事务**。在传统数据库事务中，必须要满足四个原则：

![image-20240225214035863](assets/image-20240225214035863.png)

<br/>

### 分布式事务

**分布式事务**，就是指不是在单个服务或单个数据库架构下，产生的事务，例如：

- 跨数据源的分布式事务
- 跨服务的分布式事务
- 综合情况

<br/>

在数据库水平拆分、服务垂直拆分之后，一个业务操作通常要跨多个数据库、服务才能完成。例如电商行业中比较常见的下单付款案例，包括下面几个行为：

- 创建新订单
- 扣减商品库存
- 从用户账户余额扣除金额

<br/>

完成上面的操作需要访问三个不同的微服务和三个不同的数据库。

![image-20240225214148234](assets/image-20240225214148234.png)

<br/>

订单的创建、库存的扣减、账户扣款在每一个服务和数据库内是一个本地事务，可以保证ACID原则。

但是当我们把三件事情看做一个"业务"，要满足保证“业务”的原子性，要么所有操作全部成功，要么全部失败，不允许出现部分成功部分失败的现象，这就是**分布式系统下的事务**了。

此时ACID难以满足，这是分布式事务要解决的问题。

<br/>

### 分布式事务问题

我们通过一个案例来演示分布式事务的问题：

创建数据库，名为 `seata_demo`

```SQL
create database seata_demo;
use seata_demo;
SET NAMES utf8mb4;
SET FOREIGN_KEY_CHECKS = 0;

-- ----------------------------
-- Table structure for account_tbl
-- ----------------------------
DROP TABLE IF EXISTS `account_tbl`;
CREATE TABLE `account_tbl`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `user_id` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `money` int(11) UNSIGNED NULL DEFAULT 0,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 2 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = COMPACT;

-- ----------------------------
-- Records of account_tbl
-- ----------------------------
INSERT INTO `account_tbl` VALUES (1, 'user202103032042012', 1000);

-- ----------------------------
-- Table structure for order_tbl
-- ----------------------------
DROP TABLE IF EXISTS `order_tbl`;
CREATE TABLE `order_tbl`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `user_id` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `commodity_code` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `count` int(11) NULL DEFAULT 0,
  `money` int(11) NULL DEFAULT 0,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = COMPACT;

-- ----------------------------
-- Records of order_tbl
-- ----------------------------

-- ----------------------------
-- Table structure for storage_tbl
-- ----------------------------
DROP TABLE IF EXISTS `storage_tbl`;
CREATE TABLE `storage_tbl`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `commodity_code` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `count` int(11) UNSIGNED NULL DEFAULT 0,
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE INDEX `commodity_code`(`commodity_code`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 2 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = COMPACT;

-- ----------------------------
-- Records of storage_tbl
-- ----------------------------
INSERT INTO `storage_tbl` VALUES (1, '100202003032041', 10);

SET FOREIGN_KEY_CHECKS = 1;
```

<br/>

**导入 seat-demo 基础工程**

工程源码 ：https://gitee.com/iMousse/cswiki-project/tree/master/cloud/seata-demo

微服务结构如下：

```sh
# 父工程，负责管理项目依赖
seata-demo 
│   # 账户服务，负责管理用户的资金账户。提供扣减余额的接口
├── account-service
│   # 库存服务，负责管理商品库存。提供扣减库存的接口
├── order-service
│   # 订单服务，负责管理订单。创建订单时，需要调用account-service和storage-service
└── storage-service
```

 <br/>

**测试下单功能**

启动所有工程，发送请求

```sh
curl --location --request POST 'http://localhost:8082/order?userId=user202103032042012&commodityCode=100202003032041&count=20&money=200'
```

如图

![image-20240225220219625](assets/image-20240225220219625.png)

测试发现，当库存不足时，如果余额已经扣减，并不会回滚，出现了分布式事务问题。

![image-20240225221518724](assets/image-20240225221518724.png)

<br/>

### 学习目标

![image-20240225221317520](assets/image-20240225221317520.png)



## 理论基础

解决分布式事务问题，需要一些分布式系统的基础知识作为理论指导。

### CAP定理

1998年，加州大学的计算机科学家 Eric Brewer 提出，分布式系统有三个指标。

- 一致性：Consistency
- 可用性：Availability
- 分区容错性：Partition tolerance 

它们的第一个字母分别是 C、A、P，这三个指标不可能同时做到。这个结论就叫做 CAP 定理。

![image-20240225220327324](assets/image-20240225220327324.png)

<br/>

**一致性**

Consistency（一致性）：用户访问分布式系统中的任意节点，得到的数据必须一致。

比如现在包含两个节点，其中的初始数据是一致的：

![image-20240225222040351](assets/image-20240225222040351.png)

当我们修改其中一个节点的数据时，两者的数据产生了差异：

![image-20240225222059759](assets/image-20240225222059759.png)

要想保住一致性，就必须实现 node01 到 node02 的数据同步：

![image-20240225222114637](assets/image-20240225222114637.png)

<br/>

**可用性**

Availability （可用性）：用户访问集群中的任意健康节点，必须能得到响应，而不是超时或拒绝。

如图，有三个节点的集群，访问任何一个都可以及时得到响应：

![image-20240225222158175](assets/image-20240225222158175.png)

当有部分节点因为网络故障或其它原因无法访问时，代表节点不可用：

![image-20240225222210410](assets/image-20240225222210410.png)



**分区容错**

**Partition（分区）**：因为网络故障或其它原因导致分布式系统中的部分节点与其它节点失去连接，形成独立分区。

![image-20240225222224289](assets/image-20240225222224289.png)

**Tolerance（容错）**：在集群出现分区时，整个系统也要持续对外提供服务

<br/>

**矛盾**

在分布式系统中，系统间的网络不能100%保证健康，一定会有故障的时候，而服务有必须对外保证服务。因此Partition Tolerance不可避免。

当节点接收到新的数据变更时，就会出现问题了：

![image-20240225222244210](assets/image-20240225222244210.png)

如果此时要保证**一致性**，就必须等待网络恢复，完成数据同步后，整个集群才对外提供服务，服务处于阻塞状态，不可用。

如果此时要保证**可用性**，就不能等待网络恢复，那node01、node02与node03之间就会出现数据不一致。

也就是说，在P一定会出现的情况下，A和C之间只能实现一个。

<br/>

:::warning 💡思考：简述CAP定理内容

- 分布式系统节点通过网络连接，一定会出现分区问题（P）
- 当分区出现时，系统的一致性（C）和可用性（A）就无法同时满足

**💡思考：ElasticSearch集群是CP还是AP**

- ES集群出现区分时，故障节点会被剔除集群，数据粉片会重新分配到其它节点，保证数据一致性。因此时低可用性，高一致性，属于CP

:::

<br/>

### BASE理论

BASE理论是对CAP的一种解决思路，包含三个思想：

- **Basically Available （基本可用）**：分布式系统在出现故障时，允许损失部分可用性，即保证核心可用。
- **Soft State（软状态）**：在一定时间内，允许出现中间状态，比如临时的不一致状态。
- **Eventually Consistent（最终一致性**）：虽然无法保证强一致性，但是在软状态结束后，最终达到数据一致。

<br/>

> 思考：解决分布式事务有什么思路？

分布式事务最大的问题是各个子事务的一致性问题，因此可以借鉴CAP定理和BASE理论，有两种解决思路：

- AP模式：各子事务分别执行和提交，允许出现结果不一致，然后采用弥补措施恢复数据即可，实现<mark>最终一致</mark>。

- CP模式：各个子事务执行后互相等待，同时提交，同时回滚，达成<mark>强一致</mark>。但事务等待过程中，处于弱可用状态。

<br/>

但不管是哪一种模式，都需要在子系统事务之间互相通讯，协调事务状态，也就是需要一个**事务协调者(TC)**

![image-20240225222616925](assets/image-20240225222616925.png)

这里的子系统事务，称为**分支事务**；有关联的各个分支事务在一起称为**全局事务**。



:::warning 💡思考：简述BASE理论三个思想

- 基本可用
- 软状态
- 最终一致

<br/>

💡**思考：解决分布式事务的思想和模型**

- 全局事务：整个分布式事务
- 分支事务：每个微服务的子系统的事务
- 最终一致思想：各分支事务分别执行并提交，如果有不一致的情况，再想办法恢复数据。
- 强一致思想：各分支事务执行完业务不要提交，等待彼此结果，而后统一提交或回滚。

:::



## 初识Seata

Seata是 2019 年 1 月份蚂蚁金服和阿里巴巴共同开源的分布式事务解决方案。致力于提供高性能和简单易用的分布式事务服务，为用户打造一站式的分布式解决方案。

官网地址：http://seata.io/

其中的文档、播客中提供了大量的使用说明、源码分析。

![image-20240225223249512](assets/image-20240225223249512.png)

<br/>

### Seata的架构

Seata事务管理中有三个重要的角色：

- **TC (Transaction Coordinator) -** **事务协调者：**维护全局和分支事务的状态，协调全局事务提交或回滚。

- **TM (Transaction Manager) -** **事务管理器：**定义全局事务的范围、开始全局事务、提交或回滚全局事务。

- **RM (Resource Manager) -** **资源管理器：**管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。

<br/>

**整体的架构图**

![image-20240225223810561](assets/image-20240225223810561.png)

<br/>

Seata基于上述架构提供了四种不同的分布式事务解决方案：
- XA模式：强一致性分阶段事务模式，牺牲了一定的可用性，无业务侵入
- TCC模式：最终一致的分阶段事务模式，有业务侵入
- AT模式：最终一致的分阶段事务模式，无业务侵入，也是Seata的默认模式
- SAGA模式：长事务模式，有业务侵入

无论哪种方案，都离不开TC，也就是事务的协调者。

<br/>

### 部署TC服务

[安装Seata](00操作篇-安装Seata.md)

<br/>

### 集成Seata

我们以order-service为例来演示。

安装 `Maven Helper` 插件

![image-20240225233603886](assets/image-20240225233603886.png)

<br/>

**引入依赖**

首先，在order-service中引入依赖：

```xml
<!--seata-->
<dependency>
    <groupId>com.alibaba.cloud</groupId>
    <artifactId>spring-cloud-starter-alibaba-seata</artifactId>
    <exclusions>
        <!--版本较低，1.3.0，因此排除--> 
        <exclusion>
            <artifactId>seata-spring-boot-starter</artifactId>
            <groupId>io.seata</groupId>
        </exclusion>
    </exclusions>
</dependency>
<dependency>
    <groupId>io.seata</groupId>
    <artifactId>seata-spring-boot-starter</artifactId>
    <!--seata starter 采用1.4.2版本-->
    <version>${seata.version}</version>
</dependency>
```

<br/>

**配置TC地址**

在 order-service 中的 application.yml 中，配置TC服务信息，通过注册中心 nacos，结合服务名称获取TC地址：

```yaml
seata:
  registry: # TC服务注册中心的配置，微服务根据这些信息去注册中心获取tc服务地址
    type: nacos # 注册中心类型 nacos
    nacos:
      server-addr: 127.0.0.1:8848 # nacos地址
      namespace: "" # namespace，默认为空
      group: DEFAULT_GROUP # 分组，默认是DEFAULT_GROUP
      application: seata-tc-server # seata服务名称
      username: nacos
      password: nacos
  tx-service-group: seata-demo # 事务组名称
  service:
    vgroup-mapping: # 事务组与cluster的映射关系
      seata-demo: SH
```

<br/>

微服务如何根据这些配置寻找TC的地址呢？

我们知道注册到Nacos中的微服务，确定一个具体实例需要四个信息：

- namespace：命名空间
- group：分组
- application：服务名
- cluster：集群名

<br/>

以上四个信息，在刚才的yaml文件中都能找到：

![image-20210724173654258](assets/image-20210724173654258.png)

namespace 为空，就是默认的 public

结合起来，TC服务的信息就是：`public@DEFAULT_GROUP@seata-tc-server@SH`，这样就能确定TC服务集群了。然后就可以去Nacos拉取对应的实例信息了。

<br/>

**其它服务**

其它两个微服务也都参考order-service的步骤来做，完全一样。



## 动手实践

下面我们就一起学习下Seata中的四种不同的事务模式。

<br/>

### XA模式

XA 规范 是 X/Open 组织定义的分布式事务处理（DTP，Distributed Transaction Processing）标准，XA 规范描述了全局的TM与局部的RM之间的接口，几乎所有主流的数据库都对  XA 规范提供了支持。

<br/>

#### 两阶段提交

XA是规范，目前主流数据库都实现了这种规范，实现的原理都是基于两阶段提交。

**正常情况**

![image-20240225235938600](assets/image-20240225235938600.png)

**异常情况**

![image-20240225235958664](assets/image-20240225235958664.png)

<br/>

**一阶段**

- 事务协调者通知每个事物参与者执行本地事务
- 本地事务执行完成后报告事务执行状态给事务协调者，此时事务不提交，继续持有数据库锁

**二阶段**

- 事务协调者基于一阶段的报告来判断下一步操作
  - 如果一阶段都成功，则通知所有事务参与者，提交事务
  - 如果一阶段任意一个参与者失败，则通知所有事务参与者回滚事务

<br/>

#### Seata的XA模型

Seata对原始的XA模式做了简单的封装和改造，以适应自己的事务模型，基本架构如图：

![image-20240226000023629](assets/image-20240226000023629.png)

<br/>

RM一阶段的工作：

- 注册分支事务到TC
- 执行分支业务SQL但不提交
- 报告执行状态到TC


TC二阶段的工作：

- TC检测各分支事务执行状态
  - 如果都成功，通知所有RM提交事务
  - 如果有失败，通知所有RM回滚事务


RM二阶段的工作：

- 接收TC指令，提交或回滚事务

<br/>

:::warning 💡思考：XA模式的优缺点

XA模式的优点是什么？

- 事务的强一致性，满足ACID原则。
- 常用数据库都支持，实现简单，并且没有代码侵入

XA模式的缺点是什么？

- 因为一阶段需要锁定数据库资源，等待二阶段结束才释放，性能较差
- 依赖关系型数据库实现事务

:::

<br/>

#### XA实现

Seata的starter已经完成了XA模式的自动装配，实现非常简单，步骤如下：

- 修改 `application.yml` 文件（每个参与事务的微服务），开启XA模式：


```yaml
seata:
  data-source-proxy-mode: XA
```

<br/>

- 给发起全局事务的入口方法添加 `@GlobalTransactional` 注解:


本例中是 `OrderServiceImpl` 中的 `create` 方法.

```java {16}
@Slf4j
@Service
public class OrderServiceImpl implements OrderService {

    private final AccountClient accountClient;
    private final StorageClient storageClient;
    private final OrderMapper orderMapper;

    public OrderServiceImpl(AccountClient accountClient, StorageClient storageClient, OrderMapper orderMapper) {
        this.accountClient = accountClient;
        this.storageClient = storageClient;
        this.orderMapper = orderMapper;
    }

    @Override
    @GlobalTransactional
    public Long create(Order order) {
        // 创建订单
        orderMapper.insert(order);
        try {
            // 扣用户余额
            accountClient.deduct(order.getUserId(), order.getMoney());
            // 扣库存
            storageClient.deduct(order.getCommodityCode(), order.getCount());

        } catch (FeignException e) {
            log.error("下单失败，原因:{}", e.contentUTF8(), e);
            throw new RuntimeException(e.contentUTF8(), e);
        }
        return order.getId();
    }
}

```

<br/>

- 重启服务并测试

重启三个服务，再次测试，发现无论怎样，三个微服务都能成功回滚。

<br/>

### AT模式

AT模式同样是分阶段提交的事务模型，不过缺弥补了XA模型中资源锁定周期过长的缺陷。

<br/>

#### Seata的AT模型

基本流程图：

![image-20240226001237827](assets/image-20240226001237827.png)

<br/>

阶段一RM的工作：

- 注册分支事务
- 记录 `undo-log`（数据快照）
- 执行业务sql并提交
- 报告事务状态

阶段二提交时RM的工作：

- 删除 `undo-log` 即可

阶段二回滚时RM的工作：

- 根据 `undo-log` 恢复数据到更新前

<br/>

#### 流程梳理

我们用一个真实的业务来梳理下AT模式的原理。

比如，现在又一个数据库表，记录用户余额：`{"id": 1, "money": 100}`

其中一个分支业务要执行的SQL为：

```sql
update tb_account set money = money - 10 where id = 1
```

<br/>

AT模式下，当前分支事务执行流程如下：

**一阶段**

- TM发起并注册全局事务到TC
- TM调用分支事务
- 分支事务准备执行业务SQL
- RM拦截业务SQL，根据where条件查询原始数据，形成快照
- RM执行业务SQL，提交本地事务，释放数据库锁。此时 `money = 90`
  ```json
  {
      "id": 1, "money": 100
  }
  ```
- RM报告本地事务状态给TC

<br/>

**二阶段**

- TM通知TC事务结束

- TC检查分支事务状态
  - 如果都成功，则立即删除快照
  - 如果有分支事务失败，需要回滚。读取快照数据（`{"id": 1, "money": 100}`），将快照恢复到数据库。此时数据库再次恢复为100

<br/>

**流程图**

![image-20240226010220294](assets/image-20240226010220294.png)

<br/>

:::warning 💡思考：简述AT模式与XA模式最大的区别是什么？

- XA模式一阶段不提交事务，锁定资源；AT模式一阶段直接提交，不锁定资源。
- XA模式依赖数据库机制实现回滚；AT模式利用数据快照实现数据回滚。
- XA模式强一致；AT模式最终一致

:::

<br/>

#### 脏写问题

在多线程并发访问AT模式的分布式事务时，有可能出现脏写问题，如图：

![image-20240226010320507](assets/image-20240226010320507.png)

解决思路就是引入了全局锁的概念。在释放DB锁之前，先拿到全局锁。避免同一时刻有另外一个事务来操作当前数据。

<br/>

**事务2**因为获取全局锁，需要去执行 `set money` 语句，但是**事务1**也在等待DB锁。因为**事务1**的DB锁相对**事务2**的全局锁等待时间更久，**事务2**在重试30次后自动释放了。

![image-20240226010346849](assets/image-20240226010346849.png)

- DB锁：数据库不释放，任何人都不能对数据库进行操作。
- 全局锁：Seate 在  TC 记录当前操作某行数据的事务。

<br/>

注意：如果不是 Seate 管理的事务则可以对这条数据进行操作。<mark>如果没有被 Seate 管理的事务操作了其他数据则不会被锁。</mark>比如修改其他字段，但是也可以修改金额字段，造成数据的脏写，但是这个几率很低，主要有三个方面

- 转账一般都是成功的，很少有需要回滚的场景
- 分布式事务，链路比较长，耗时比较久，并发比较低
- 在做业务尽量避免多个业务去操作同一个字段，可以通过代码规范来进行避免。

<br/>


但是 Seate 也有方案来进行避免

![image-20240226010413874](assets/image-20240226010413874.png)

<br/>

:::warning 💡思考：AT模式优缺点

AT模式的优点：

- 一阶段完成直接提交事务，释放数据库资源，性能比较好
- 利用全局锁实现读写隔离
- 没有代码侵入，框架自动完成回滚和提交

AT模式的缺点：

- 两阶段之间属于软状态，属于最终一致
- 框架的快照功能会影响性能，但比XA模式要好很多

:::

<br/>

#### AT实现

AT模式中的快照生成、回滚等动作都是由框架自动完成，没有任何代码侵入，因此实现非常简单。

只不过，AT模式需要一个表来记录全局锁、另一张表来记录数据快照 `undo_log`。

<br/>

- 导入数据库表，记录全局锁：[Seata-V1.4.2-Client-AT-DB-脚本](https://github.com/apache/incubator-seata/tree/v1.4.2/script/client/at/db)

其中 `lock_table` 导入到TC服务关联的数据库，`undo_log` 表导入到微服务关联的数据库：

```java
SET NAMES utf8mb4;
SET FOREIGN_KEY_CHECKS = 0;

-- ----------------------------
-- Table structure for undo_log
-- ----------------------------
DROP TABLE IF EXISTS `undo_log`;
CREATE TABLE `undo_log`  (
  `branch_id` bigint(20) NOT NULL COMMENT 'branch transaction id',
  `xid` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT 'global transaction id',
  `context` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT 'undo_log context,such as serialization',
  `rollback_info` longblob NOT NULL COMMENT 'rollback info',
  `log_status` int(11) NOT NULL COMMENT '0:normal status,1:defense status',
  `log_created` datetime(6) NOT NULL COMMENT 'create datetime',
  `log_modified` datetime(6) NOT NULL COMMENT 'modify datetime',
  UNIQUE INDEX `ux_undo_log`(`xid`, `branch_id`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = 'AT transaction mode undo table' ROW_FORMAT = Compact;

-- ----------------------------
-- Records of undo_log
-- ----------------------------

-- ----------------------------
-- Table structure for lock_table
-- ----------------------------
DROP TABLE IF EXISTS `lock_table`;
CREATE TABLE `lock_table`  (
  `row_key` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `xid` varchar(96) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `transaction_id` bigint(20) NULL DEFAULT NULL,
  `branch_id` bigint(20) NOT NULL,
  `resource_id` varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `table_name` varchar(32) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `pk` varchar(36) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `gmt_create` datetime NULL DEFAULT NULL,
  `gmt_modified` datetime NULL DEFAULT NULL,
  PRIMARY KEY (`row_key`) USING BTREE,
  INDEX `idx_branch_id`(`branch_id`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;


SET FOREIGN_KEY_CHECKS = 1;
```

<br/>

- 修改 `application.yml` 文件，将事务模式修改为AT模式即可：

```yaml
seata:
  data-source-proxy-mode: AT # 默认就是AT
```

<br/>

- 重启服务并测试


<br/>

### TCC模式

TCC模式与AT模式非常相似，每阶段都是独立事务，不同的是TCC通过人工编码来实现数据恢复。需要实现三个方法：

- Try：资源的检测和预留； 
- Confirm：完成资源操作业务；要求 Try 成功 Confirm 一定要能成功。
- Cancel：预留资源释放，可以理解为try的反向操作。

<br/>

#### 流程分析

举例，一个扣减用户余额的业务。假设账户A原来余额是100，需要余额扣减30元。

- **阶段一（ Try ）**：检查余额是否充足，如果充足则冻结金额增加30元，可用余额扣除30

初识余额：

![image-20210724182424907](assets/image-20210724182424907.png)

余额充足，可以冻结：

![image-20210724182457951](assets/image-20210724182457951.png)

此时，总金额 = 冻结金额 + 可用金额，数量依然是100不变。事务直接提交无需等待其它事务。

<br/>

- **阶段二（Confirm)**：假如要提交（Confirm），则冻结金额扣减30

确认可以提交，不过之前可用金额已经扣减过了，这里只要清除冻结金额就好了：

![image-20210724182706011](assets/image-20210724182706011.png)

此时，总金额 = 冻结金额 + 可用金额 = 0 + 70  = 70元

<br/>

- **阶段二(Canncel)**：如果要回滚（Cancel），则冻结金额扣减30，可用余额增加30

需要回滚，那么就要释放冻结金额，恢复可用金额：

![image-20210724182810734](assets/image-20210724182810734.png)

<br/>

#### Seata的TCC模型

[TCC 理论及设计实现指南介绍 (seata.io)](http://seata.io/zh-cn/blog/tcc-mode-design-principle.html)

Seata中的TCC模型依然延续之前的事务架构，如图：

![image-20240226014550201](assets/image-20240226014550201.png)

<br/>

:::warning 💡思考：TCC模式的优缺点

**TCC模式的每个阶段是做什么的？**

- Try：资源检查和预留
- Confirm：业务执行和提交
- Cancel：预留资源的释放

<br/>

**TCC的优点是什么？**

- 一阶段完成直接提交事务，释放数据库资源，性能好
- 相比AT模型，无需生成快照，无需使用全局锁，性能最强
- 不依赖数据库事务，而是依赖补偿操作，可以用于非事务型数据库

<br/>

**TCC的缺点是什么？**

- 有代码侵入，需要人为编写 Try、Confirm 和 Cancel 接口，太麻烦
- 软状态，事务是最终一致
- 需要考虑 Confirm 和 Cancel 的失败情况，做好幂等处理

:::

<br/>

#### TCC实现

改造 `account-service` 服务，利用TCC实现分布式事务

需求如下：

- 修改account-service，编写 Try、Confirm、Cancel 逻辑
- Try 业务：添加冻结金额，扣减可用金额
- Confirm 业务：删除冻结金额
- Cancel 业务：删除冻结金额，恢复可用金额
- 保证 Confirm、Cancel 接口的<font color="red">幂等性</font>
- 允许<font color="red">空回滚</font>
- 拒绝<font color="red">业务悬挂</font>

<br/>

##### 空回滚

当某分支事务的 Try 阶段**阻塞**时，可能导致全局事务超时而触发二阶段的 Cancel 操作。在未执行 Try 操作时先执行了 Cancel 操作，这时 Cancel 不能做回滚，就是**空回滚**。

![image-20240226015341149](assets/image-20240226015341149.png)

执行 Cancel 操作时，应当判断 Try 是否已经执行，如果尚未执行，则应该空回滚。

<br/>

##### 业务悬挂

对于已经空回滚的业务，之前被阻塞的Try操作恢复，继续执行 Try，就永远不可能 Confirm 或 Cancel ，事务一直处于中间状态，这就是**业务悬挂**。

执行 Try 操作时，应当判断 Cancel 是否已经执行过了，如果已经执行，应当阻止空回滚后的 Try 操作，避免悬挂。

<br/>

解决空回滚和业务悬挂问题，必须要记录当前事务状态，是在 Try、还是 Cancel？

<br/>

##### 业务分析

![image-20240226014656090](assets/image-20240226014656090.png)

<br/>

##### 思路分析

这里我们定义一张表：

```sql
SET NAMES utf8mb4;
SET FOREIGN_KEY_CHECKS = 0;

-- ----------------------------
-- Table structure for account_freeze_tbl
-- ----------------------------
DROP TABLE IF EXISTS `account_freeze_tbl`;
CREATE TABLE `account_freeze_tbl`  (
  `xid` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `user_id` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `freeze_money` int(11) UNSIGNED NULL DEFAULT 0,
  `state` int(1) NULL DEFAULT NULL COMMENT '事务状态，0:try，1:confirm，2:cancel',
  PRIMARY KEY (`xid`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = COMPACT;

-- ----------------------------
-- Records of account_freeze_tbl
-- ----------------------------

SET FOREIGN_KEY_CHECKS = 1;
```

其中：

- `xid`：是全局事务id

- `freeze_money`：用来记录用户冻结金额，UNSIGNED则不需要判断为负数

- `state`：用来记录事务状态

<br/>

:::warning 💡思考：那此时，我们的业务开怎么做呢？

- Try 业务
  - 记录冻结金额和事务状态到 account_freeze 表
  - 扣减 account 表可用金额
- Confirm 业务
  - 根据 xid 删除 account_freeze表 的冻结记录
- Cancel 业务
  - 修改 account_freeze 表，冻结金额为 0，state 为2
  - 修改 account 表，恢复可用金额
- 如何判断是否空回滚？
  - cancel 业务中，根据 xid 查询 account_freeze，如果为 null 则说明 try 还没做，需要空回滚
- 如何避免业务悬挂？
  - try 业务中，根据 xid 查询 account_freeze ，如果已经存在则证明 Cancel已经执行，拒绝执行try业务

:::

<br/>

接下来，我们改造 `account-service` ，利用TCC实现余额扣减功能。

<br/>

##### 声明接口

TCC的Try、Confirm、Cancel方法都需要在接口中基于注解来声明，

我们在 `account-service` 项目中的`cn.itcast.account.service`包中新建一个接口，声明TCC三个接口：

```java
@LocalTCC
public interface TCCService {
    
    /**
     * Try逻辑，@TwoPhaseBusinessAction 中的name属性要与当前方法名一致，用于指定Try逻辑对应的方法
     */
    @TwoPhaseBusinessAction(name = "deduct", commitMethod = "confirm", rollbackMethod = "cancel")
    void deduct(@BusinessActionContextParameter(paramName = "userId") String userId,
                @BusinessActionContextParameter(paramName = "money") int money);

    /**
     * 二阶段confirm确认方法、可以另命名，但要保证与 commitMethod 一致
     *
     * @param context 上下文,可以传递try方法的参数
     * @return boolean 执行是否成功
     */
    boolean confirm(BusinessActionContext context);

    /**
     * 二阶段回滚方法，要保证与 rollbackMethod 一致
     */
    boolean cancel(BusinessActionContext context);
}
```

<br/>

##### 编写实现类

在 `account-service` 服务中的 `cn.itcast.account.service.impl` 包下新建一个类。

实现TCC的Try、Confirm、Cancel方法

```java
package cn.itcast.account.service.impl;

import cn.itcast.account.entity.AccountFreeze;
import cn.itcast.account.mapper.AccountFreezeMapper;
import cn.itcast.account.mapper.AccountMapper;
import cn.itcast.account.service.AccountTCCService;
import io.seata.core.context.RootContext;
import io.seata.rm.tcc.api.BusinessActionContext;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

@Service
@Slf4j
public class AccountTCCServiceImpl implements AccountTCCService {

    @Autowired
    private AccountMapper accountMapper;
    @Autowired
    private AccountFreezeMapper freezeMapper;

    @Override
    @Transactional
    public void deduct(String userId, int money) {
        // 0.获取事务id
        String xid = RootContext.getXID();

        // 1.扣减可用余额
        accountMapper.deduct(userId, money);
      
        // 2.记录冻结金额，事务状态
        AccountFreeze freeze = new AccountFreeze();
        freeze.setUserId(userId);
        freeze.setFreezeMoney(money);
        freeze.setState(AccountFreeze.State.TRY);
        freeze.setXid(xid);
        freezeMapper.insert(freeze);
    }

    @Override
    public boolean confirm(BusinessActionContext ctx) {
        // 1.获取事务id
        String xid = ctx.getXid();
      
        // 2.根据id删除冻结记录
        int count = freezeMapper.deleteById(xid);
        return count == 1;
    }

    @Override
    public boolean cancel(BusinessActionContext ctx) {
        // 0.查询冻结记录
        String xid = ctx.getXid();
        AccountFreeze freeze = freezeMapper.selectById(xid);

        // 1.恢复可用余额
        accountMapper.refund(freeze.getUserId(), freeze.getFreezeMoney());
      
        // 2.将冻结金额清零，状态改为CANCEL
        freeze.setFreezeMoney(0);
        freeze.setState(AccountFreeze.State.CANCEL);
        int count = freezeMapper.updateById(freeze);
        return count == 1;
    }
}

```

<br/>

实现TCC的幂等，实现空回滚，拒绝业务悬挂

```java {29-33,62-72,74-78}
package cn.itcast.account.service.impl;

import cn.itcast.account.entity.AccountFreeze;
import cn.itcast.account.mapper.AccountFreezeMapper;
import cn.itcast.account.mapper.AccountMapper;
import cn.itcast.account.service.AccountTCCService;
import io.seata.core.context.RootContext;
import io.seata.rm.tcc.api.BusinessActionContext;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

@Service
@Slf4j
public class AccountTCCServiceImpl implements AccountTCCService {

    @Autowired
    private AccountMapper accountMapper;
    @Autowired
    private AccountFreezeMapper freezeMapper;

    @Override
    @Transactional
    public void deduct(String userId, int money) {
        // 0.获取事务id
        String xid = RootContext.getXID();

        // 判断freeze中是否有冻结记录，如果有一定是CANCEL执行过，要拒绝业务
        AccountFreeze oldFreeze = freezeMapper.selectById(xid);
        if (oldFreeze != null) {
            return;
        }
      
        // 1.扣减可用余额
        accountMapper.deduct(userId, money);
      
        // 2.记录冻结金额，事务状态
        AccountFreeze freeze = new AccountFreeze();
        freeze.setUserId(userId);
        freeze.setFreezeMoney(money);
        freeze.setState(AccountFreeze.State.TRY);
        freeze.setXid(xid);
        freezeMapper.insert(freeze);
    }

    @Override
    public boolean confirm(BusinessActionContext ctx) {
        // 1.获取事务id
        String xid = ctx.getXid();
        // 2.根据id删除冻结记录
        int count = freezeMapper.deleteById(xid);
        return count == 1;
    }

    @Override
    public boolean cancel(BusinessActionContext ctx) {
        // 0.查询冻结记录
        String xid = ctx.getXid();
        AccountFreeze freeze = freezeMapper.selectById(xid);

        // 空回滚的判断，判断freeze是否为空，为null则证明try没有执行，需要空回滚
        if (freeze == null) {
            String userId = ctx.getActionContext("userId").toString();
            freeze = new AccountFreeze();
            freeze.setXid(xid);
            freeze.setUserId(userId);
            freeze.setFreezeMoney(0);
            freeze.setState(AccountFreeze.State.CANCEL);
            freezeMapper.insert(freeze);
            return true;
        }

        // 幂等判断
        if (freeze.getState().equals(AccountFreeze.State.CANCEL)) {
            //已经处理过一次CANCEL，无需重复处理
            return true;
        }

        // 1.恢复可用余额
        accountMapper.refund(freeze.getUserId(), freeze.getFreezeMoney());
       
        // 2.将冻结金额清零，状态改为CANCEL
        freeze.setFreezeMoney(0);
        freeze.setState(AccountFreeze.State.CANCEL);
        int count = freezeMapper.updateById(freeze);
        return count == 1;
    }
}
```

<br/>

### SAGA模式

Saga 模式是 Seata 即将开源的长事务解决方案，将由蚂蚁金服主要贡献。

其理论基础是Hector & Kenneth  在1987年发表的论文[Sagas](https://microservices.io/patterns/data/saga.html)。

Seata官网对于Saga的指南：https://seata.io/zh-cn/docs/user/saga.html

<br/>

#### 原理

在 Saga 模式下，分布式事务内有多个参与者，每一个参与者都是一个冲正补偿服务，需要用户根据业务场景实现其正向操作和逆向回滚操作。

分布式事务执行过程中，依次执行各参与者的正向操作，如果所有正向操作均执行成功，那么分布式事务提交。如果任何一个正向操作执行失败，那么分布式事务会去退回去执行前面各参与者的逆向回滚操作，回滚已提交的参与者，使分布式事务回到初始状态。

![image-20210724184846396](assets/image-20210724184846396.png)

Saga也分为两个阶段：

- 一阶段：直接提交本地事务
- 二阶段：成功则什么都不做；失败则通过编写补偿业务来回滚

<br/>

:::warning 💡思考：SAGA模式的优缺点

优点：

- 事务参与者可以基于事件驱动实现异步调用，吞吐高
- 一阶段直接提交事务，无锁，性能好
- 不用编写TCC中的三个阶段，实现简单

缺点：

- 软状态持续时间不确定，时效性差
- 没有锁，没有事务隔离，会有脏写

:::



### 四种模式对比

我们从以下几个方面来对比四种实现：

- 一致性：能否保证事务的一致性？强一致还是最终一致？
- 隔离性：事务之间的隔离性如何？
- 代码侵入：是否需要对业务代码改造？
- 性能：有无性能损耗？
- 场景：常见的业务场景

<br/>

**如图**

![image-20240226231302526](assets/image-20240226231302526.png)



## 高可用

Seata的TC服务作为分布式事务核心，一定要保证集群的高可用性。

<br/>

### 高可用架构模型

搭建TC服务集群非常简单，启动多个TC服务，注册到nacos即可。

但集群并不能确保100%安全，万一集群所在机房故障怎么办？所以如果要求较高，一般都会做异地多机房容灾。

比如一个TC集群在上海，另一个TC集群在杭州：

![image-20240226231327165](assets/image-20240226231327165.png)

<br/>

微服务基于事务组`tx-service-group` 与TC集群的映射关系，来查找当前应该使用哪个TC集群。当SH集群故障时，只需要将 `vgroup-mapping` 中的映射关系改成HZ。则所有微服务就会切换到HZ的TC集群了。

<br/>

### 实现高可用

#### 模拟异地容灾的TC集群

计划启动两台seata的tc服务节点：

| 节点名称 | ip地址    | 端口号 | 集群名称 |
| -------- | --------- | ------ | -------- |
| seata    | 127.0.0.1 | 8091   | SH       |
| seata2   | 127.0.0.1 | 8092   | HZ       |

之前我们已经启动了一台seata服务，端口是8091，集群名为SH。

现在，将seata目录复制一份，起名为seata2

<br/>

修改 `seata2/conf/registry.conf` 内容如下：

```nginx
registry {
  # tc服务的注册中心类，这里选择nacos，也可以是eureka、zookeeper等
  type = "nacos"

  nacos {
    # seata tc 服务注册到 nacos的服务名称，可以自定义
    application = "seata-tc-server"
    serverAddr = "127.0.0.1:8848"
    group = "DEFAULT_GROUP"
    namespace = ""
    cluster = "HZ"
    username = "nacos"
    password = "nacos"
  }
}

config {
  # 读取tc服务端的配置文件的方式，这里是从nacos配置中心读取，这样如果tc是集群，可以共享配置
  type = "nacos"
  # 配置nacos地址等信息
  nacos {
    serverAddr = "127.0.0.1:8848"
    namespace = ""
    group = "SEATA_GROUP"
    username = "nacos"
    password = "nacos"
    dataId = "seataServer.properties"
  }
}
```

<br/>

进入 `seata2/bin` 目录，然后运行命令：

```powershell
seata-server.bat -p 8092
```

<br/>

打开nacos控制台，查看服务列表：

![image-20210624151150840](assets/image-20210624151150840.png)

点进详情查看：

![image-20210624151221747](assets/image-20210624151221747.png)

<br/>

#### 将事务组映射配置到nacos

接下来，我们需要将 `tx-service-group` 与 `cluster` 的映射关系都配置到 `nacos` 配置中心。

<br/>

新建一个配置

![image-20210624151507072](assets/image-20210624151507072.png)

<br/>

配置的内容如下

```properties
# 事务组映射关系
service.vgroupMapping.seata-demo=SH

service.enableDegrade=false
service.disableGlobalTransaction=false
# 与TC服务的通信配置
transport.type=TCP
transport.server=NIO
transport.heartbeat=true
transport.enableClientBatchSendRequest=false
transport.threadFactory.bossThreadPrefix=NettyBoss
transport.threadFactory.workerThreadPrefix=NettyServerNIOWorker
transport.threadFactory.serverExecutorThreadPrefix=NettyServerBizHandler
transport.threadFactory.shareBossWorker=false
transport.threadFactory.clientSelectorThreadPrefix=NettyClientSelector
transport.threadFactory.clientSelectorThreadSize=1
transport.threadFactory.clientWorkerThreadPrefix=NettyClientWorkerThread
transport.threadFactory.bossThreadSize=1
transport.threadFactory.workerThreadSize=default
transport.shutdown.wait=3
# RM配置
client.rm.asyncCommitBufferLimit=10000
client.rm.lock.retryInterval=10
client.rm.lock.retryTimes=30
client.rm.lock.retryPolicyBranchRollbackOnConflict=true
client.rm.reportRetryCount=5
client.rm.tableMetaCheckEnable=false
client.rm.tableMetaCheckerInterval=60000
client.rm.sqlParserType=druid
client.rm.reportSuccessEnable=false
client.rm.sagaBranchRegisterEnable=false
# TM配置
client.tm.commitRetryCount=5
client.tm.rollbackRetryCount=5
client.tm.defaultGlobalTransactionTimeout=60000
client.tm.degradeCheck=false
client.tm.degradeCheckAllowTimes=10
client.tm.degradeCheckPeriod=2000

# undo日志配置
client.undo.dataValidation=true
client.undo.logSerialization=jackson
client.undo.onlyCareUpdateColumns=true
client.undo.logTable=undo_log
client.undo.compress.enable=true
client.undo.compress.type=zip
client.undo.compress.threshold=64k
client.log.exceptionRate=100
```

<br/>

#### 微服务读取nacos配置

接下来，需要修改每一个微服务的application.yml文件，让微服务读取nacos中的client.properties文件：

```yaml
seata:
  config:
    type: nacos
    nacos:
      server-addr: 127.0.0.1:8848
      username: nacos
      password: nacos
      group: SEATA_GROUP
      data-id: client.properties
```

重启微服务，现在微服务到底是连接tc的SH集群，还是tc的HZ集群，都统一由nacos的client.properties来决定了。





